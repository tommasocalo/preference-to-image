{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/tcalo3/projects/project6')\n",
    "sys.path.append('/home/tcalo3/projects/project6/src/modules/components/ganspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StyleGAN2: Optimized CUDA op FusedLeakyReLU not available, using native PyTorch fallback.\n",
      "StyleGAN2: Optimized CUDA op UpFirDn2d not available, using native PyTorch fallback.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "from IPython.utils import io\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from models import get_instrumented_model\n",
    "from decomposition import get_or_compute\n",
    "from config import Config\n",
    "from skimage import img_as_ubyte\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.acquisition.monte_carlo import qUpperConfidenceBound\n",
    "import warnings\n",
    "import numpy as np\n",
    "import math\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.models.pairwise_gp import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Speed up computation\n",
    "torch.autograd.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Specify model to use\n",
    "config = Config(\n",
    "  model='StyleGAN',\n",
    "  layer='g_mapping.dense7',\n",
    "  output_class='ffhq',\n",
    "  components=32,\n",
    "  use_w=True,\n",
    "  batch_size=5_000, # style layer quite small\n",
    ")\n",
    "\n",
    "inst = get_instrumented_model(config.model, config.output_class,\n",
    "                              config.layer, torch.device('cuda'), use_w=config.use_w)\n",
    "\n",
    "path_to_components = get_or_compute(config, inst)\n",
    "\n",
    "model = inst.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.metrics.models.facenet import FaceNetModel\n",
    "\n",
    "def sample_pca_space(n_samples, pca_components, pca_stdevs):\n",
    "    random_samples = np.random.randn(n_samples, pca_components) * pca_stdevs\n",
    "    return random_samples\n",
    "\n",
    "def reconstruct_from_pca(pca_samples, pca_components, data_mean):\n",
    "    original_data = np.dot(pca_samples, pca_components) + data_mean\n",
    "    return original_data\n",
    "\n",
    "\n",
    "def project_to_pca(new_data, pca_components, data_mean):\n",
    "    centered_data = new_data - data_mean\n",
    "    pca_projection = np.dot(centered_data, pca_components.T)\n",
    "    return pca_projection\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    facenet = FaceNetModel().eval()\n",
    "    pass\n",
    "\n",
    "\n",
    "def reconstruct_and_evaluate(X,target,latent_dirs,latent_stdevs,eval_model):\n",
    "    target_out = model.sample_np(target)\n",
    "    target_image = Image.fromarray((target_out * 255).astype(np.uint8))\n",
    "    target_resized_image = target_image.resize((160, 160), Image.NEAREST)\n",
    "    target_tensor = torch.from_numpy(np.array(target_resized_image)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    target_embedding = facenet(target_tensor.float())\n",
    "\n",
    "    X = reconstruct_from_pca(X,comps['lat_comp'][:,0,:].T,comps['lat_mean'])\n",
    "    X_out = model.sample_np(X.astype(np.float32))\n",
    "    X_image = Image.fromarray((X_out * 255).astype(np.uint8))\n",
    "    X_resized_image = X_image.resize((160, 160), Image.NEAREST)\n",
    "    X_tensor = torch.from_numpy(np.array(X_resized_image)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    X_embedding = facenet(X_tensor.float())\n",
    "\n",
    "    return torch.nn.functional.cosine_similarity(target_embedding, X_embedding, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps['lat_comp'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latent_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps['lat_stdev'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Component No. 28\n"
     ]
    }
   ],
   "source": [
    "#@title Load a component at random\n",
    "path_to_components=\"/home/tcalo3/projects/project6/src/modules/components/ganspace/cache/components/stylegan-ffhq_g_mapping.dense7_pca-full_c32_n300000_w.npz\"\n",
    "comps = np.load(path_to_components)\n",
    "\n",
    "latent_dirs = comps['lat_comp'][:,0,:]\n",
    "latent_stdevs = comps['lat_stdev']\n",
    "data_mean = comps['lat_mean']\n",
    "\n",
    "#load one at random\n",
    "dims = latent_stdevs.shape[0]\n",
    "num = np.random.randint(dims)\n",
    "random_dir = latent_dirs[num]\n",
    "random_dir_stdev = latent_stdevs[num]\n",
    "print(f'Loaded Component No. {num}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reconstruct_and_evaluate(x, target, model, latent_dirs,eval_model, data_mean):\n",
    "    target_out = model.sample_np(target)\n",
    "    target_image = Image.fromarray((target_out * 255).astype(np.uint8))\n",
    "    target_resized_image = target_image.resize((160, 160), Image.NEAREST)\n",
    "    target_tensor = torch.from_numpy(np.array(target_resized_image)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    target_embedding = eval_model(target_tensor.float())\n",
    "\n",
    "    x_reconstructed = reconstruct_from_pca(x,latent_dirs,data_mean)\n",
    "    x_gan = model.sample_np(x_reconstructed.astype(np.float32))\n",
    "    x_image = Image.fromarray((x_gan * 255).astype(np.uint8))\n",
    "    x_resized_image = x_image.resize((160, 160), Image.NEAREST)\n",
    "    x_tensor = torch.from_numpy(np.array(x_resized_image)).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    x_embedding = eval_model(x_tensor.float())\n",
    "\n",
    "    return torch.nn.functional.cosine_similarity(target_embedding, x_embedding, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = model.sample_latent(1).cpu().detach().numpy() \n",
    "# Generate initial training data\n",
    "train_x = sample_pca_space(1,dims,latent_stdevs)\n",
    "\n",
    "# Parameters\n",
    "num_arms = dims\n",
    "max_steps = 1000\n",
    "c = 1.5\n",
    "\n",
    "# Initialize variables\n",
    "Q_a = np.zeros(num_arms)\n",
    "N_a = np.zeros(num_arms)\n",
    "total_rewards = 0\n",
    "\n",
    "q_a = np.array([np.random.normal(0, 1) for _ in range(num_arms)])\n",
    "\n",
    "# Function to select action using the Upper Confidence Bound algorithm\n",
    "def select_action(t):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        upper_confidence_bounds = Q_a + c * np.sqrt(np.log(t) / N_a)\n",
    "    return np.argmax(upper_confidence_bounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = model.sample_latent(1).cpu().detach().numpy() \n",
    "# y_pca = project_to_pca(target,latent_dirs,data_mean)\n",
    "# y_reconstructed = reconstruct_from_pca(y_pca,latent_dirs,data_mean)\n",
    "y_gan =  model.sample_np(target.astype(np.float32))\n",
    "y_image = Image.fromarray((y_gan * 255).astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca = sample_pca_space(1,dims,latent_stdevs)\n",
    "x_reconstructed = reconstruct_from_pca(x_pca,latent_dirs,data_mean)\n",
    "x_gan = model.sample_np(x_reconstructed.astype(np.float32))\n",
    "x_image = Image.fromarray((x_gan * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'inputs' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m train_x \u001b[38;5;241m=\u001b[39m sample_pca_space(\u001b[38;5;241m1\u001b[39m,dims,latent_stdevs)\n\u001b[1;32m      4\u001b[0m train_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming the initial image is favored or assumed as a baseline comparison\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m gp_model \u001b[38;5;241m=\u001b[39m \u001b[43mPairwiseGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/project6_env/lib/python3.9/site-packages/botorch/models/pairwise_gp.py:256\u001b[0m, in \u001b[0;36mPairwiseGP.__init__\u001b[0;34m(self, datapoints, comparisons, likelihood, covar_module, input_transform, jitter, xtol, consolidate_rtol, consolidate_atol, maxfev)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconsolidated_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# See set_train_data for additional compatibility variables.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Not that the datapoints here are not transformed even if input_transform\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# is not None to avoid double transformation during model fitting.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# self.transform_inputs is called in `forward`\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomparisons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Set hyperparameters\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# Do not set the batch_shape explicitly so mean_module can operate in both mode\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# once fsolve used in _update can run in batch mode, we should explicitly set\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# the bacth shape here\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_module \u001b[38;5;241m=\u001b[39m ConstantMean()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/project6_env/lib/python3.9/site-packages/botorch/models/pairwise_gp.py:855\u001b[0m, in \u001b[0;36mPairwiseGP.set_train_data\u001b[0;34m(self, datapoints, comparisons, strict, update_model)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(datapoints):\n\u001b[1;32m    851\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [datapoints]\n\u001b[1;32m    853\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    854\u001b[0m     input_\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m input_\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m input_\n\u001b[0;32m--> 855\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m input_ \u001b[38;5;129;01min\u001b[39;00m \u001b[43minputs\u001b[49m\n\u001b[1;32m    856\u001b[0m )\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m    858\u001b[0m     _check_strict_input(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_inputs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'inputs' referenced before assignment"
     ]
    }
   ],
   "source": [
    "step = 0 \n",
    "action = select_action(step)\n",
    "train_x = sample_pca_space(1,dims,latent_stdevs)\n",
    "train_y = torch.tensor([0])  # Assuming the initial image is favored or assumed as a baseline comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "def pull_arm(dimension, pca_components, pca_stdevs, data_mean, objective_function, train_x, train_y, bounds):\n",
    "    # Assume the most recent or best values for other dimensions are stored in train_x\n",
    "    if train_x is None:\n",
    "        # Initial sampling for all dimensions\n",
    "        current_values = torch.zeros(1, pca_components.shape[1])\n",
    "    else:\n",
    "        # Start with the last known best values\n",
    "        current_values = train_x[-1].unsqueeze(0).clone()  \n",
    "\n",
    "    # Create a GP model from the existing data\n",
    "    gp_model = SingleTaskGP(train_x, train_y)\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "    fit_gpytorch_model(mll)\n",
    "\n",
    "    # Define the acquisition function\n",
    "    EI = ExpectedImprovement(model=gp_model, best_f=train_y.max())\n",
    "\n",
    "    # Optimize the acquisition function, modifying only the selected dimension\n",
    "    # Set bounds for only the selected dimension to vary\n",
    "    lower_bounds, upper_bounds = bounds[:, 0], bounds[:, 1]\n",
    "    fixed_bounds = torch.stack([lower_bounds, upper_bounds], dim=-1)\n",
    "    fixed_bounds[:, dimension] = torch.tensor([bounds[dimension, 0], bounds[dimension, 1]])  # Only free this dimension\n",
    "\n",
    "    # Optimize using the acquisition function\n",
    "    candidate, _ = optimize_acqf(\n",
    "        acq_function=EI,\n",
    "        bounds=fixed_bounds,\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=512,\n",
    "    )\n",
    "\n",
    "    # Update only the selected dimension with the new candidate\n",
    "    current_values[0, dimension] = candidate[0, dimension]\n",
    "\n",
    "    # Evaluate the objective function using the updated values\n",
    "    train_x_reconstructed = reconstruct_from_pca(current_values.numpy(), pca_components[:, dimension].T, data_mean)\n",
    "    reward = objective_function(train_x_reconstructed, data_mean)\n",
    "\n",
    "    # Update training data\n",
    "    train_x = torch.cat([train_x, current_values], dim=0)\n",
    "    train_y = torch.cat([train_y, torch.tensor([reward])], dim=0)\n",
    "\n",
    "    return reward, current_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "num_arms = dims\n",
    "max_steps = 1000\n",
    "c = 1.5\n",
    "\n",
    "# Initialize variables\n",
    "Q_a = np.zeros(num_arms)\n",
    "N_a = np.zeros(num_arms)\n",
    "total_rewards = 0\n",
    "\n",
    "q_a = np.array([np.random.normal(0, 1) for _ in range(num_arms)])\n",
    "\n",
    "def pull_arm(dimension, pca_components, pca_stdevs, data_mean, objective_function, train_x, train_y, bounds, target):\n",
    "    # Sample initial point in PCA space and modify it along the selected arm\n",
    "    if train_x is None:\n",
    "        train_x_dim = torch.zeros(1, pca_components.shape[0])\n",
    "    else:\n",
    "        train_x_dim = train_x[-1].clone()\n",
    "\n",
    "    # Define the pairwise GP model using existing data\n",
    "    gp_model = PairwiseGP(train_x, train_y)\n",
    "    \n",
    "    # Define the acquisition function\n",
    "    mll = PairwiseLaplaceMarginalLogLikelihood(gp_model.likelihood,gp_model)\n",
    "    mll = fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Optimize the acquisition function\n",
    "    pca_sample = sample_pca_space(1, pca_components.shape[1], pca_stdevs)  # Start with a new sample\n",
    "    train_x_dim[0, dimension] = pca_sample[0, dimension]  # Adjust only the selected dimension\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        acq_function=mll,\n",
    "        bounds=torch.tensor([bounds[:, dimension]]).to(torch.float32),\n",
    "        q=1,\n",
    "        num_restarts=10,\n",
    "        raw_samples=512,\n",
    "    )\n",
    "\n",
    "    # Use the optimized candidate to update the dimension in train_x\n",
    "    train_x_dim[0, dimension] = candidate.squeeze()\n",
    "\n",
    "    # Reconstruct the full sample from PCA and evaluate the objective\n",
    "    train_x_reconstructed = reconstruct_from_pca(train_x_dim.numpy(), pca_components[:, dimension].T, data_mean)\n",
    "    reward = objective_function(train_x_reconstructed, target)\n",
    "\n",
    "    # Update the training data\n",
    "    if train_x is None:\n",
    "        train_x = train_x_dim.unsqueeze(0)\n",
    "        train_y = torch.tensor([reward])\n",
    "    else:\n",
    "        train_x = torch.cat([train_x, train_x_dim.unsqueeze(0)], dim=0)\n",
    "        train_y = torch.cat([train_y, torch.tensor([reward])], dim=0)\n",
    "\n",
    "    return reward, train_x_dim\n",
    "\n",
    "\n",
    "# Function to select action using the Upper Confidence Bound algorithm\n",
    "def select_action(t):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        upper_confidence_bounds = Q_a + c * np.sqrt(np.log(t) / N_a)\n",
    "    return np.argmax(upper_confidence_bounds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = model.sample_latent(1).cpu().detach().numpy() \n",
    "# Generate initial training data\n",
    "pca_sample = sample_pca_space(1,dims,latent_stdevs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Running the bandit algorithm\n",
    "for step in range(1, max_steps):\n",
    "    action = select_action(step)\n",
    "    current_reward = pull_arm(action)\n",
    "    total_rewards[action] += current_reward\n",
    "    N_a[action] += 1\n",
    "    Q_a[action] += (current_reward - Q_a[action]) / N_a[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project6_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
